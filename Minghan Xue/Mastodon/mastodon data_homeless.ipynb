{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a324ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# List of JSON files to be merged\n",
    "json_files = [\"aussocial_homeless_data.json\", \"mastodonau_homeless_data.json\", \"theblower_homeless_data.json\"]\n",
    "\n",
    "data = []\n",
    "for file in json_files:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data.extend(json.load(f))  # Adds the data from the current file to the list\n",
    "\n",
    "# Write the combined data to a new file\n",
    "with open(\"combined_homeless_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05986ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file\n",
    "input_file = \"combined_homeless_data.json\"\n",
    "\n",
    "data = []\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    all_data = json.load(f)\n",
    "    for item in all_data:\n",
    "        id_value = item.get(\"id\", None)\n",
    "        created_at_value = item.get(\"created_at\", None)\n",
    "        if id_value and created_at_value:\n",
    "            data.append({\"id\": id_value, \"created_at\": created_at_value})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df3788d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '110347624531815443', 'created_at': '2023-05-11T02:12:05.000Z'},\n",
       " {'id': '110341335099811284', 'created_at': '2023-05-09T23:32:35.000Z'},\n",
       " {'id': '110339164090559930', 'created_at': '2023-05-09T14:20:25.000Z'},\n",
       " {'id': '110339162650836354', 'created_at': '2023-05-09T14:20:02.000Z'},\n",
       " {'id': '110337906453291583', 'created_at': '2023-05-09T09:00:37.000Z'},\n",
       " {'id': '110331421817194767', 'created_at': '2023-05-08T05:31:31.000Z'},\n",
       " {'id': '110330423222347570', 'created_at': '2023-05-08T01:17:34.000Z'},\n",
       " {'id': '110329728388287106', 'created_at': '2023-05-07T22:20:48.000Z'},\n",
       " {'id': '110329726527403469', 'created_at': '2023-05-07T22:20:19.000Z'},\n",
       " {'id': '110327902689561528', 'created_at': '2023-05-07T14:36:29.000Z'},\n",
       " {'id': '110327898299694175', 'created_at': '2023-05-07T14:35:22.000Z'},\n",
       " {'id': '110327051674279222', 'created_at': '2023-05-07T11:00:07.000Z'},\n",
       " {'id': '110326291255785780', 'created_at': '2023-05-07T07:46:43.000Z'},\n",
       " {'id': '110326191529333124', 'created_at': '2023-05-07T07:21:24.000Z'},\n",
       " {'id': '110325185355972511', 'created_at': '2023-05-07T03:05:30.000Z'},\n",
       " {'id': '110325180605890126', 'created_at': '2023-05-07T03:04:17.000Z'},\n",
       " {'id': '110324845507746524', 'created_at': '2023-05-07T01:39:05.000Z'},\n",
       " {'id': '110323642090379427', 'created_at': '2023-05-06T20:33:02.000Z'},\n",
       " {'id': '110323134614458653', 'created_at': '2023-05-06T18:23:59.000Z'},\n",
       " {'id': '110322849848854992', 'created_at': '2023-05-06T17:11:33.000Z'},\n",
       " {'id': '110347624531815443', 'created_at': '2023-05-11T02:12:05.000Z'},\n",
       " {'id': '110341335099811284', 'created_at': '2023-05-09T23:32:35.000Z'},\n",
       " {'id': '110339164090559930', 'created_at': '2023-05-09T14:20:25.000Z'},\n",
       " {'id': '110339162650836354', 'created_at': '2023-05-09T14:20:02.000Z'},\n",
       " {'id': '110337906453291583', 'created_at': '2023-05-09T09:00:37.000Z'},\n",
       " {'id': '110331421817194767', 'created_at': '2023-05-08T05:31:31.000Z'},\n",
       " {'id': '110330423222347570', 'created_at': '2023-05-08T01:17:34.000Z'},\n",
       " {'id': '110329728388287106', 'created_at': '2023-05-07T22:20:48.000Z'},\n",
       " {'id': '110329726527403469', 'created_at': '2023-05-07T22:20:19.000Z'},\n",
       " {'id': '110327902689561528', 'created_at': '2023-05-07T14:36:29.000Z'},\n",
       " {'id': '110327898299694175', 'created_at': '2023-05-07T14:35:22.000Z'},\n",
       " {'id': '110327051674279222', 'created_at': '2023-05-07T11:00:07.000Z'},\n",
       " {'id': '110326291255785780', 'created_at': '2023-05-07T07:46:43.000Z'},\n",
       " {'id': '110326191529333124', 'created_at': '2023-05-07T07:21:24.000Z'},\n",
       " {'id': '110325185355972511', 'created_at': '2023-05-07T03:05:30.000Z'},\n",
       " {'id': '110325180605890126', 'created_at': '2023-05-07T03:04:17.000Z'},\n",
       " {'id': '110324845507746524', 'created_at': '2023-05-07T01:39:05.000Z'},\n",
       " {'id': '110323642090379427', 'created_at': '2023-05-06T20:33:02.000Z'},\n",
       " {'id': '110323134614458653', 'created_at': '2023-05-06T18:23:59.000Z'},\n",
       " {'id': '110322849848854992', 'created_at': '2023-05-06T17:11:33.000Z'},\n",
       " {'id': '110347624531815443', 'created_at': '2023-05-11T02:12:05.000Z'},\n",
       " {'id': '110341335099811284', 'created_at': '2023-05-09T23:32:35.000Z'},\n",
       " {'id': '110339164090559930', 'created_at': '2023-05-09T14:20:25.000Z'},\n",
       " {'id': '110339162650836354', 'created_at': '2023-05-09T14:20:02.000Z'},\n",
       " {'id': '110337906453291583', 'created_at': '2023-05-09T09:00:37.000Z'},\n",
       " {'id': '110331421817194767', 'created_at': '2023-05-08T05:31:31.000Z'},\n",
       " {'id': '110330423222347570', 'created_at': '2023-05-08T01:17:34.000Z'},\n",
       " {'id': '110329728388287106', 'created_at': '2023-05-07T22:20:48.000Z'},\n",
       " {'id': '110329726527403469', 'created_at': '2023-05-07T22:20:19.000Z'},\n",
       " {'id': '110327902689561528', 'created_at': '2023-05-07T14:36:29.000Z'},\n",
       " {'id': '110327898299694175', 'created_at': '2023-05-07T14:35:22.000Z'},\n",
       " {'id': '110327051674279222', 'created_at': '2023-05-07T11:00:07.000Z'},\n",
       " {'id': '110326291255785780', 'created_at': '2023-05-07T07:46:43.000Z'},\n",
       " {'id': '110326191529333124', 'created_at': '2023-05-07T07:21:24.000Z'},\n",
       " {'id': '110325185355972511', 'created_at': '2023-05-07T03:05:30.000Z'},\n",
       " {'id': '110325180605890126', 'created_at': '2023-05-07T03:04:17.000Z'},\n",
       " {'id': '110324845507746524', 'created_at': '2023-05-07T01:39:05.000Z'},\n",
       " {'id': '110323642090379427', 'created_at': '2023-05-06T20:33:02.000Z'},\n",
       " {'id': '110323134614458653', 'created_at': '2023-05-06T18:23:59.000Z'},\n",
       " {'id': '110322849848854992', 'created_at': '2023-05-06T17:11:33.000Z'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58a01cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id                created_at\n",
      "0   110347624531815443  2023-05-11T02:12:05.000Z\n",
      "1   110341335099811284  2023-05-09T23:32:35.000Z\n",
      "2   110339164090559930  2023-05-09T14:20:25.000Z\n",
      "3   110339162650836354  2023-05-09T14:20:02.000Z\n",
      "4   110337906453291583  2023-05-09T09:00:37.000Z\n",
      "5   110331421817194767  2023-05-08T05:31:31.000Z\n",
      "6   110330423222347570  2023-05-08T01:17:34.000Z\n",
      "7   110329728388287106  2023-05-07T22:20:48.000Z\n",
      "8   110329726527403469  2023-05-07T22:20:19.000Z\n",
      "9   110327902689561528  2023-05-07T14:36:29.000Z\n",
      "10  110327898299694175  2023-05-07T14:35:22.000Z\n",
      "11  110327051674279222  2023-05-07T11:00:07.000Z\n",
      "12  110326291255785780  2023-05-07T07:46:43.000Z\n",
      "13  110326191529333124  2023-05-07T07:21:24.000Z\n",
      "14  110325185355972511  2023-05-07T03:05:30.000Z\n",
      "15  110325180605890126  2023-05-07T03:04:17.000Z\n",
      "16  110324845507746524  2023-05-07T01:39:05.000Z\n",
      "17  110323642090379427  2023-05-06T20:33:02.000Z\n",
      "18  110323134614458653  2023-05-06T18:23:59.000Z\n",
      "19  110322849848854992  2023-05-06T17:11:33.000Z\n",
      "20  110347624531815443  2023-05-11T02:12:05.000Z\n",
      "21  110341335099811284  2023-05-09T23:32:35.000Z\n",
      "22  110339164090559930  2023-05-09T14:20:25.000Z\n",
      "23  110339162650836354  2023-05-09T14:20:02.000Z\n",
      "24  110337906453291583  2023-05-09T09:00:37.000Z\n",
      "25  110331421817194767  2023-05-08T05:31:31.000Z\n",
      "26  110330423222347570  2023-05-08T01:17:34.000Z\n",
      "27  110329728388287106  2023-05-07T22:20:48.000Z\n",
      "28  110329726527403469  2023-05-07T22:20:19.000Z\n",
      "29  110327902689561528  2023-05-07T14:36:29.000Z\n",
      "30  110327898299694175  2023-05-07T14:35:22.000Z\n",
      "31  110327051674279222  2023-05-07T11:00:07.000Z\n",
      "32  110326291255785780  2023-05-07T07:46:43.000Z\n",
      "33  110326191529333124  2023-05-07T07:21:24.000Z\n",
      "34  110325185355972511  2023-05-07T03:05:30.000Z\n",
      "35  110325180605890126  2023-05-07T03:04:17.000Z\n",
      "36  110324845507746524  2023-05-07T01:39:05.000Z\n",
      "37  110323642090379427  2023-05-06T20:33:02.000Z\n",
      "38  110323134614458653  2023-05-06T18:23:59.000Z\n",
      "39  110322849848854992  2023-05-06T17:11:33.000Z\n",
      "40  110347624531815443  2023-05-11T02:12:05.000Z\n",
      "41  110341335099811284  2023-05-09T23:32:35.000Z\n",
      "42  110339164090559930  2023-05-09T14:20:25.000Z\n",
      "43  110339162650836354  2023-05-09T14:20:02.000Z\n",
      "44  110337906453291583  2023-05-09T09:00:37.000Z\n",
      "45  110331421817194767  2023-05-08T05:31:31.000Z\n",
      "46  110330423222347570  2023-05-08T01:17:34.000Z\n",
      "47  110329728388287106  2023-05-07T22:20:48.000Z\n",
      "48  110329726527403469  2023-05-07T22:20:19.000Z\n",
      "49  110327902689561528  2023-05-07T14:36:29.000Z\n",
      "50  110327898299694175  2023-05-07T14:35:22.000Z\n",
      "51  110327051674279222  2023-05-07T11:00:07.000Z\n",
      "52  110326291255785780  2023-05-07T07:46:43.000Z\n",
      "53  110326191529333124  2023-05-07T07:21:24.000Z\n",
      "54  110325185355972511  2023-05-07T03:05:30.000Z\n",
      "55  110325180605890126  2023-05-07T03:04:17.000Z\n",
      "56  110324845507746524  2023-05-07T01:39:05.000Z\n",
      "57  110323642090379427  2023-05-06T20:33:02.000Z\n",
      "58  110323134614458653  2023-05-06T18:23:59.000Z\n",
      "59  110322849848854992  2023-05-06T17:11:33.000Z\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217cfee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id  created_at\n",
      "0   110347624531815443  2023.05.11\n",
      "1   110341335099811284  2023.05.09\n",
      "2   110339164090559930  2023.05.09\n",
      "3   110339162650836354  2023.05.09\n",
      "4   110337906453291583  2023.05.09\n",
      "5   110331421817194767  2023.05.08\n",
      "6   110330423222347570  2023.05.08\n",
      "7   110329728388287106  2023.05.07\n",
      "8   110329726527403469  2023.05.07\n",
      "9   110327902689561528  2023.05.07\n",
      "10  110327898299694175  2023.05.07\n",
      "11  110327051674279222  2023.05.07\n",
      "12  110326291255785780  2023.05.07\n",
      "13  110326191529333124  2023.05.07\n",
      "14  110325185355972511  2023.05.07\n",
      "15  110325180605890126  2023.05.07\n",
      "16  110324845507746524  2023.05.07\n",
      "17  110323642090379427  2023.05.06\n",
      "18  110323134614458653  2023.05.06\n",
      "19  110322849848854992  2023.05.06\n",
      "20  110347624531815443  2023.05.11\n",
      "21  110341335099811284  2023.05.09\n",
      "22  110339164090559930  2023.05.09\n",
      "23  110339162650836354  2023.05.09\n",
      "24  110337906453291583  2023.05.09\n",
      "25  110331421817194767  2023.05.08\n",
      "26  110330423222347570  2023.05.08\n",
      "27  110329728388287106  2023.05.07\n",
      "28  110329726527403469  2023.05.07\n",
      "29  110327902689561528  2023.05.07\n",
      "30  110327898299694175  2023.05.07\n",
      "31  110327051674279222  2023.05.07\n",
      "32  110326291255785780  2023.05.07\n",
      "33  110326191529333124  2023.05.07\n",
      "34  110325185355972511  2023.05.07\n",
      "35  110325180605890126  2023.05.07\n",
      "36  110324845507746524  2023.05.07\n",
      "37  110323642090379427  2023.05.06\n",
      "38  110323134614458653  2023.05.06\n",
      "39  110322849848854992  2023.05.06\n",
      "40  110347624531815443  2023.05.11\n",
      "41  110341335099811284  2023.05.09\n",
      "42  110339164090559930  2023.05.09\n",
      "43  110339162650836354  2023.05.09\n",
      "44  110337906453291583  2023.05.09\n",
      "45  110331421817194767  2023.05.08\n",
      "46  110330423222347570  2023.05.08\n",
      "47  110329728388287106  2023.05.07\n",
      "48  110329726527403469  2023.05.07\n",
      "49  110327902689561528  2023.05.07\n",
      "50  110327898299694175  2023.05.07\n",
      "51  110327051674279222  2023.05.07\n",
      "52  110326291255785780  2023.05.07\n",
      "53  110326191529333124  2023.05.07\n",
      "54  110325185355972511  2023.05.07\n",
      "55  110325180605890126  2023.05.07\n",
      "56  110324845507746524  2023.05.07\n",
      "57  110323642090379427  2023.05.06\n",
      "58  110323134614458653  2023.05.06\n",
      "59  110322849848854992  2023.05.06\n"
     ]
    }
   ],
   "source": [
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df['created_at'] = df['created_at'].dt.strftime('%Y.%m.%d')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b4df3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   created_at  homeless_count\n",
      "0  2023.05.06               9\n",
      "1  2023.05.07              30\n",
      "2  2023.05.08               6\n",
      "3  2023.05.09              12\n",
      "4  2023.05.11               3\n"
     ]
    }
   ],
   "source": [
    "df_count = df.groupby('created_at').size().reset_index(name='homeless_count')\n",
    "\n",
    "print(df_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27e78d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [\"aussocial_mortgage_data.json\", \"mastodonau_mortgage_data.json\", \"theblower_mortgage_data.json\"]\n",
    "\n",
    "data = []\n",
    "for file in json_files:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data.extend(json.load(f))  # Adds the data from the current file to the list\n",
    "\n",
    "# Write the combined data to a new file\n",
    "with open(\"combined_mortgage_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False)\n",
    "    input_file = \"combined_mortgage_data.json\"\n",
    "\n",
    "data = []\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    all_data = json.load(f)\n",
    "    for item in all_data:\n",
    "        id_value = item.get(\"id\", None)\n",
    "        created_at_value = item.get(\"created_at\", None)\n",
    "        if id_value and created_at_value:\n",
    "            data.append({\"id\": id_value, \"created_at\": created_at_value})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ce22b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   created_at  mortgage_count\n",
      "0  2023.04.29               3\n",
      "1  2023.04.30               6\n",
      "2  2023.05.04               3\n",
      "3  2023.05.05               3\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.DataFrame(data)\n",
    "df_1['created_at'] = pd.to_datetime(df_1['created_at'])\n",
    "df_1['created_at'] = df_1['created_at'].dt.strftime('%Y.%m.%d')\n",
    "df_count_1 = df_1.groupby('created_at').size().reset_index(name='mortgage_count')\n",
    "\n",
    "print(df_count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73cfac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [\"aussocial_rent_data.json\", \"mastodonau_rent_data.json\", \"theblower_rent_data.json\"]\n",
    "\n",
    "data = []\n",
    "for file in json_files:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data.extend(json.load(f))  # Adds the data from the current file to the list\n",
    "\n",
    "# Write the combined data to a new file\n",
    "with open(\"combined_rent_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False)\n",
    "    input_file = \"combined_rent_data.json\"\n",
    "\n",
    "data = []\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    all_data = json.load(f)\n",
    "    for item in all_data:\n",
    "        id_value = item.get(\"id\", None)\n",
    "        created_at_value = item.get(\"created_at\", None)\n",
    "        if id_value and created_at_value:\n",
    "            data.append({\"id\": id_value, \"created_at\": created_at_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac2d274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    created_at  rent_count\n",
      "0   2022.11.09           3\n",
      "1   2023.04.27           3\n",
      "2   2023.04.28           6\n",
      "3   2023.04.29           9\n",
      "4   2023.05.02           3\n",
      "5   2023.05.03           3\n",
      "6   2023.05.04           3\n",
      "7   2023.05.05           3\n",
      "8   2023.05.07           6\n",
      "9   2023.05.09           9\n",
      "10  2023.05.10           3\n"
     ]
    }
   ],
   "source": [
    "df_2 = pd.DataFrame(data)\n",
    "df_2['created_at'] = pd.to_datetime(df_2['created_at'])\n",
    "df_2['created_at'] = df_2['created_at'].dt.strftime('%Y.%m.%d')\n",
    "df_count_2 = df_2.groupby('created_at').size().reset_index(name='rent_count')\n",
    "\n",
    "print(df_count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9584ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [\"aussocial_income_data.json\", \"mastodonau_income_data.json\", \"theblower_income_data.json\"]\n",
    "\n",
    "data = []\n",
    "for file in json_files:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data.extend(json.load(f))  # Adds the data from the current file to the list\n",
    "\n",
    "# Write the combined data to a new file\n",
    "with open(\"combined_income_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False)\n",
    "    input_file = \"combined_income_data.json\"\n",
    "\n",
    "data = []\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    all_data = json.load(f)\n",
    "    for item in all_data:\n",
    "        id_value = item.get(\"id\", None)\n",
    "        created_at_value = item.get(\"created_at\", None)\n",
    "        if id_value and created_at_value:\n",
    "            data.append({\"id\": id_value, \"created_at\": created_at_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b87f1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   created_at  income_count\n",
      "0  2023.04.27             3\n",
      "1  2023.05.02             6\n",
      "2  2023.05.03             3\n"
     ]
    }
   ],
   "source": [
    "df_3 = pd.DataFrame(data)\n",
    "df_3['created_at'] = pd.to_datetime(df_3['created_at'])\n",
    "df_3['created_at'] = df_3['created_at'].dt.strftime('%Y.%m.%d')\n",
    "df_count_3 = df_3.groupby('created_at').size().reset_index(name='income_count')\n",
    "\n",
    "print(df_count_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f71c4579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>homeless_count</th>\n",
       "      <th>mortgage_count</th>\n",
       "      <th>rent_count</th>\n",
       "      <th>income_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023.05.06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023.05.07</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023.05.08</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023.05.09</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023.05.11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023.04.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023.04.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023.05.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023.05.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022.11.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023.04.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023.04.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023.04.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023.05.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023.05.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023.05.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023.05.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023.05.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023.05.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023.05.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023.04.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023.05.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023.05.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    created_at  homeless_count  mortgage_count  rent_count  income_count\n",
       "0   2023.05.06             9.0             NaN         NaN           NaN\n",
       "1   2023.05.07            30.0             NaN         NaN           NaN\n",
       "2   2023.05.08             6.0             NaN         NaN           NaN\n",
       "3   2023.05.09            12.0             NaN         NaN           NaN\n",
       "4   2023.05.11             3.0             NaN         NaN           NaN\n",
       "5   2023.04.29             NaN             3.0         NaN           NaN\n",
       "6   2023.04.30             NaN             6.0         NaN           NaN\n",
       "7   2023.05.04             NaN             3.0         NaN           NaN\n",
       "8   2023.05.05             NaN             3.0         NaN           NaN\n",
       "9   2022.11.09             NaN             NaN         3.0           NaN\n",
       "10  2023.04.27             NaN             NaN         3.0           NaN\n",
       "11  2023.04.28             NaN             NaN         6.0           NaN\n",
       "12  2023.04.29             NaN             NaN         9.0           NaN\n",
       "13  2023.05.02             NaN             NaN         3.0           NaN\n",
       "14  2023.05.03             NaN             NaN         3.0           NaN\n",
       "15  2023.05.04             NaN             NaN         3.0           NaN\n",
       "16  2023.05.05             NaN             NaN         3.0           NaN\n",
       "17  2023.05.07             NaN             NaN         6.0           NaN\n",
       "18  2023.05.09             NaN             NaN         9.0           NaN\n",
       "19  2023.05.10             NaN             NaN         3.0           NaN\n",
       "20  2023.04.27             NaN             NaN         NaN           3.0\n",
       "21  2023.05.02             NaN             NaN         NaN           6.0\n",
       "22  2023.05.03             NaN             NaN         NaN           3.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.concat([df_count, df_count_1, df_count_2, df_count_3], ignore_index=True)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ecc3421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_new = df_combined.sort_values('created_at')\n",
    "\n",
    "# Replace NaN values with 0\n",
    "df_new = df_combined_new.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e5ead2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>homeless_count</th>\n",
       "      <th>mortgage_count</th>\n",
       "      <th>rent_count</th>\n",
       "      <th>income_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022.11.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023.04.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023.04.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023.04.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023.04.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023.04.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023.04.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023.05.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023.05.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023.05.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023.05.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023.05.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023.05.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023.05.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023.05.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023.05.06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023.05.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023.05.07</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023.05.08</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023.05.09</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023.05.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023.05.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023.05.11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          time  homeless_count  mortgage_count  rent_count  income_count\n",
       "9   2022.11.09             0.0             0.0         3.0           0.0\n",
       "20  2023.04.27             0.0             0.0         0.0           3.0\n",
       "10  2023.04.27             0.0             0.0         3.0           0.0\n",
       "11  2023.04.28             0.0             0.0         6.0           0.0\n",
       "12  2023.04.29             0.0             0.0         9.0           0.0\n",
       "5   2023.04.29             0.0             3.0         0.0           0.0\n",
       "6   2023.04.30             0.0             6.0         0.0           0.0\n",
       "13  2023.05.02             0.0             0.0         3.0           0.0\n",
       "21  2023.05.02             0.0             0.0         0.0           6.0\n",
       "14  2023.05.03             0.0             0.0         3.0           0.0\n",
       "22  2023.05.03             0.0             0.0         0.0           3.0\n",
       "7   2023.05.04             0.0             3.0         0.0           0.0\n",
       "15  2023.05.04             0.0             0.0         3.0           0.0\n",
       "16  2023.05.05             0.0             0.0         3.0           0.0\n",
       "8   2023.05.05             0.0             3.0         0.0           0.0\n",
       "0   2023.05.06             9.0             0.0         0.0           0.0\n",
       "17  2023.05.07             0.0             0.0         6.0           0.0\n",
       "1   2023.05.07            30.0             0.0         0.0           0.0\n",
       "2   2023.05.08             6.0             0.0         0.0           0.0\n",
       "3   2023.05.09            12.0             0.0         0.0           0.0\n",
       "18  2023.05.09             0.0             0.0         9.0           0.0\n",
       "19  2023.05.10             0.0             0.0         3.0           0.0\n",
       "4   2023.05.11             3.0             0.0         0.0           0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df_new.rename(columns={'created_at': 'time'})\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "358b8c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('mastodon data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbeb7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv\n",
    "\n",
    "def csv_to_json(csv_file_path):\n",
    "    data = []\n",
    "    with open(csv_file_path, mode='r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "def write_json_file(json_file_path, data):\n",
    "    with open(json_file_path, mode='w', encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    csv_file_path = 'mastodon data.csv'\n",
    "    json_file_path = 'mastodon data.json'\n",
    "\n",
    "    data = csv_to_json(csv_file_path)\n",
    "    write_json_file(json_file_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8d7061f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e03e944',\n",
       "  '1-bb446a8cbf21abec9f616e95a6883801'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e03ef63',\n",
       "  '1-d6c5a2469e1fe6ab826bbfd848354691'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e03fa6e',\n",
       "  '1-f0a32b3398572cea071910009a89acbd'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e040341',\n",
       "  '1-a96068a27f3d55c2a17321dc80d5f4fa'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e0411da',\n",
       "  '1-b04a2167041372f23d0bdfcb71c8408f'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e041fe7',\n",
       "  '1-26f6bbe05269ebf5806d2a48f6cb96be'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e042a9a',\n",
       "  '1-d05db25cdeaca4e4170d23cba1b4323e'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e0433c5',\n",
       "  '1-904b215aa371ea52900fafb94d5447b2'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e043629',\n",
       "  '1-ad738d9951a1870e9134d43e6282a4ea'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e043a58',\n",
       "  '1-b5a5ba1be65586794fdfd291e5e6730b'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e0447ca',\n",
       "  '1-c804ad80bfbc9efef28c950e4f3ed5cb'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e0451c7',\n",
       "  '1-ffb58e4215a702497666e0395657f6e9'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e04538e',\n",
       "  '1-11b59bf1f58f4dbf2790a55415845d02'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e04542c',\n",
       "  '1-00c9c0ffcd0a5065e0b3f0de7fb528c7'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e045b34',\n",
       "  '1-6dbff4679bb23bb554b72153ed29f5f1'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e0469c4',\n",
       "  '1-ed2a53508d8b66bd02fdd7806909927a'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e047561',\n",
       "  '1-13d04a9698b2c2cb6707ce8e2b9ff8fe'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e048507',\n",
       "  '1-fd4bac553ac92ad8ea21f56be2fbb4b7'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e048701',\n",
       "  '1-4fbdd5237a936496aa4dab71037a63e4'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e048cb9',\n",
       "  '1-335bea309ea13ba7362e79b7e6dc571a'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e049bb0',\n",
       "  '1-58b0148d98f226bee2f0ed0997b4a235'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e04aa22',\n",
       "  '1-d1af5f37a94f0a2eafdb5e54e719c478'),\n",
       " (True,\n",
       "  '1e3a2dc0609eb5baeab98f9f8e04aff3',\n",
       "  '1-25879eec96d31457b346754a1ffc016e')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import couchdb\n",
    "import json\n",
    "\n",
    "# 连接到CouchDB服务器\n",
    "couch = couchdb.Server('http://jionghao:123456@172.26.130.66:5984')\n",
    "\n",
    "# 创建或选择数据库\n",
    "db_name = 'mastodon_data'\n",
    "if db_name in couch:\n",
    "    db = couch[db_name]\n",
    "else:\n",
    "    db = couch.create(db_name)\n",
    "\n",
    "# 加载JSON数据\n",
    "with open('mastodon data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 批量插入数据\n",
    "db.update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 读取数据并将\"time\"列转换为日期时间类型\n",
    "df_new['time'] = pd.to_datetime(df_new['time'])\n",
    "\n",
    "# 将\"time\"列设置为索引\n",
    "df_new = df_new.set_index('time')\n",
    "\n",
    "# 绘制时间序列图\n",
    "df_new.plot(figsize=(10, 6))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Time Series')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ac89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# 拟合ARIMA模型\n",
    "model = ARIMA(df_new['homeless_count'], order=(1, 1, 1))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# 进行预测\n",
    "predictions = model_fit.predict(start=pd.to_datetime('2023-04-30'), end=pd.to_datetime('2023-05-11'))\n",
    "\n",
    "# 绘制原始数据和预测结果\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_new.index, df_new['homeless_count'], label='Actual')\n",
    "plt.plot(predictions.index, predictions, label='Predicted')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Count')\n",
    "plt.title('ARIMA Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
